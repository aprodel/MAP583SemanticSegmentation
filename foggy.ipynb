{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "\n",
    "from functions import *\n",
    "from utils import *\n",
    "sys.path.append(\"/model\")\n",
    "from deeplab_plus import *\n",
    "from deeplabv3 import *\n",
    "sys.path.append(\"/import\")\n",
    "from datasets import *\n",
    "from fog_datasets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_val_batches: 1487\n",
      "pretrained resnet, 18\n"
     ]
    }
   ],
   "source": [
    "n_epoch=1\n",
    "\n",
    "batch_size = 2\n",
    "\n",
    "lr=1e-3\n",
    "\n",
    "val_dataset = DatasetTrain(cityscapes_data_path=\"small_cityscapes\",\n",
    "                         cityscapes_meta_path=\"small_meta\")\n",
    "                         \n",
    "fog_dataset = DatasetTrain_fog(cityscapes_data_path=\"small_cityscapes_foggy\")\n",
    "\n",
    "num_val_batches = int(len(val_dataset)/batch_size)\n",
    "print (\"num_val_batches:\", num_val_batches)\n",
    "\n",
    "dataloader_source = torch.utils.data.DataLoader(dataset=val_dataset,\n",
    "                                         batch_size=batch_size, shuffle=False,\n",
    "num_workers=1)\n",
    "\n",
    "dataloader_target = torch.utils.data.DataLoader(dataset=fog_dataset,\n",
    "                                         batch_size=batch_size, shuffle=False,\n",
    "num_workers=1)\n",
    "                \n",
    "network = DeepLab_Plus(\"eval_val\", project_dir=\"save\").cuda()\n",
    "\n",
    "\n",
    "with open('small_meta/class_weights.pkl', 'rb') as file:\n",
    "    class_weights = np.array(pickle.load(file))\n",
    "class_weights = torch.from_numpy(class_weights)\n",
    "class_weights = Variable(class_weights.type(torch.FloatTensor)).cuda()\n",
    "\n",
    "# loss function\n",
    "loss_fn = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = optim.Adam(network.parameters(), lr=lr)\n",
    "loss_dn = torch.nn.NLLLoss()\n",
    "\n",
    "for p in network.parameters():\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 512, 1024])\n",
      "torch.Size([3, 512, 1024])\n"
     ]
    }
   ],
   "source": [
    "print(val_dataset[0][0].shape)\n",
    "print(fog_dataset[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 512, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cleme\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:2351: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
      "C:\\Users\\cleme\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:2423: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 512, 64, 128])\n",
      "torch.Size([2, 8, 64, 128])\n",
      "torch.Size([2, 8, 9, 18])\n",
      "torch.Size([2, 1296])\n",
      "torch.Size([2, 2])\n",
      "torch.Size([2, 2])\n",
      "torch.Size([2, 20, 512, 1024])\n",
      "torch.Size([2, 512, 1024])\n",
      "torch.Size([2, 512, 64, 128])\n",
      "torch.Size([2, 8, 64, 128])\n",
      "torch.Size([2, 8, 9, 18])\n",
      "torch.Size([2, 1296])\n",
      "torch.Size([2, 2])\n",
      "torch.Size([2, 2])\n",
      "epoch: 0, [iter: 1 / all 1488], err_s_label: 0.453235, err_s_domain: 1.000949, err_t_domain: 0.545539\n",
      "torch.Size([2, 3, 512, 1024])\n",
      "torch.Size([2, 512, 64, 128])\n",
      "torch.Size([2, 8, 64, 128])\n",
      "torch.Size([2, 8, 9, 18])\n",
      "torch.Size([2, 1296])\n",
      "torch.Size([2, 2])\n",
      "torch.Size([2, 2])\n",
      "torch.Size([2, 20, 512, 1024])\n",
      "torch.Size([2, 512, 1024])\n",
      "torch.Size([2, 512, 64, 128])\n",
      "torch.Size([2, 8, 64, 128])\n",
      "torch.Size([2, 8, 9, 18])\n",
      "torch.Size([2, 1296])\n",
      "torch.Size([2, 2])\n",
      "torch.Size([2, 2])\n",
      "epoch: 0, [iter: 2 / all 1488], err_s_label: 0.394108, err_s_domain: 0.918871, err_t_domain: 0.458511\n"
     ]
    }
   ],
   "source": [
    "err_tot=[]\n",
    "err_s_label_tot=[]\n",
    "err_t_domain_tot=[]\n",
    "err_s_domain_tot=[]\n",
    "for epoch in range(n_epoch):\n",
    "\n",
    "    len_dataloader = min(len(dataloader_source), len(dataloader_target))\n",
    "    data_source_iter = iter(dataloader_source)\n",
    "    data_target_iter = iter(dataloader_target)\n",
    "\n",
    "    i = 0\n",
    "    while i < len_dataloader:\n",
    "        if i>1:\n",
    "            break\n",
    "        with torch.no_grad():\n",
    "            p = float(i + epoch * len_dataloader) / n_epoch / len_dataloader\n",
    "            alpha = 2. / (1. + np.exp(-10 * p)) - 1\n",
    "        \n",
    "            # training model using source data\n",
    "            \n",
    "            data_source = data_source_iter.next()\n",
    "            s_img, s_label,s_id = data_source\n",
    "            print(s_img.shape)\n",
    "            \n",
    "            network.zero_grad()\n",
    "            \n",
    "            # (corresponds to setting volatile=True in all variables, this is done during inference to reduce memory consumption)\n",
    "            s_img = Variable(s_img).cuda() # (shape: (batch_size, 3, img_h, img_w))\n",
    "            s_label = Variable(s_label.type(torch.LongTensor)).cuda() # (shape: (batch_size, img_h, img_w))\n",
    "\n",
    "            domain_label = torch.zeros(batch_size)\n",
    "            domain_label = domain_label.long()\n",
    "            domain_label=Variable(domain_label).cuda()\n",
    "            \n",
    "\n",
    "            outputs, domain_output = network(x=s_img,alpha=alpha) # (shape: (batch_size, num_classes, img_h, img_w))\n",
    "            \n",
    "            # compute the loss:\n",
    "            print(outputs.shape)\n",
    "            print(s_label.shape)\n",
    "            err_s_label = loss_fn(outputs, s_label)\n",
    "            \n",
    "            err_s_domain=loss_dn(domain_output, domain_label)\n",
    "            \n",
    "            # training model using target data\n",
    "            data_target = data_target_iter.next()\n",
    "            t_img, _ ,t_id= data_target\n",
    "            \n",
    "            domain_label = torch.ones(batch_size)\n",
    "            domain_label = domain_label.long()\n",
    "        \n",
    "            input_img = Variable(t_img).cuda()\n",
    "            domain_label = Variable(domain_label).cuda()\n",
    "            \n",
    "            _, domain_output = network(x=t_img, alpha=alpha)\n",
    "            \n",
    "            err_t_domain = loss_dn(domain_output, domain_label)\n",
    "            err = err_t_domain + err_s_domain + err_s_label\n",
    "            err_tot.append(err)\n",
    "            err_s_label_tot.append(err_s_label)\n",
    "            err_t_domain_tot.append(err_t_domain)\n",
    "            err_s_domain_tot.append(err_s_domain)\n",
    "            err=Variable(err,requires_grad = True).cuda()\n",
    "            err.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            i += 1\n",
    "        \n",
    "            print ('epoch: %d, [iter: %d / all %d], err_s_label: %f, err_s_domain: %f, err_t_domain: %f' \\\n",
    "                    % (epoch, i, len_dataloader, err_s_label.cpu().data.numpy(),\n",
    "        err_s_domain.cpu().data.numpy(), err_t_domain.cpu().data.numpy()))\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vall_dataset = DatasetVal(cityscapes_data_path=\"small_cityscapes\",\n",
    "                         cityscapes_meta_path=\"small_meta\")\n",
    "                         \n",
    "fogg_dataset = DatasetVal_fog(cityscapes_data_path=\"small_cityscapes_foggy\")\n",
    "\n",
    "without_fog = torch.utils.data.DataLoader(dataset=vall_dataset,\n",
    "                                         batch_size=batch_size, shuffle=False,\n",
    "num_workers=1)\n",
    "\n",
    "with_fog = torch.utils.data.DataLoader(dataset=fogg_dataset,\n",
    "                                         batch_size=batch_size, shuffle=False,\n",
    "num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepLab_Plus(\n",
       "  (network): DeepLabV3(\n",
       "    (resnet): ResNet_BasicBlock_OS8(\n",
       "      (resnet): Sequential(\n",
       "        (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace)\n",
       "        (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "        (4): Sequential(\n",
       "          (0): BasicBlock(\n",
       "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (1): BasicBlock(\n",
       "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (5): Sequential(\n",
       "          (0): BasicBlock(\n",
       "            (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): BasicBlock(\n",
       "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential()\n",
       "        )\n",
       "      )\n",
       "      (layer5): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (aspp): ASPP(\n",
       "      (conv_1x1_1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn_conv_1x1_1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv_3x3_1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
       "      (bn_conv_3x3_1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv_3x3_2): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12))\n",
       "      (bn_conv_3x3_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv_3x3_3): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18))\n",
       "      (bn_conv_3x3_3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "      (conv_1x1_2): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn_conv_1x1_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv_1x1_3): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn_conv_1x1_3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv_1x1_4): Conv2d(256, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (conv1): Conv2d(512, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc): Linear(in_features=1296, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainId_to_id = {\n",
    "    0: 7,\n",
    "    1: 8,\n",
    "    2: 11,\n",
    "    3: 12,\n",
    "    4: 13,\n",
    "    5: 17,\n",
    "    6: 19,\n",
    "    7: 20,\n",
    "    8: 21,\n",
    "    9: 22,\n",
    "    10: 23,\n",
    "    11: 24,\n",
    "    12: 25,\n",
    "    13: 26,\n",
    "    14: 27,\n",
    "    15: 28,\n",
    "    16: 31,\n",
    "    17: 32,\n",
    "    18: 33,\n",
    "    19: 0\n",
    "}\n",
    "trainId_to_id_map_func = np.vectorize(trainId_to_id.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 512, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cleme\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:2351: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
      "C:\\Users\\cleme\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:2423: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 512, 64, 128])\n",
      "torch.Size([2, 8, 64, 128])\n",
      "torch.Size([2, 8, 9, 18])\n",
      "torch.Size([2, 1296])\n",
      "torch.Size([2, 2])\n",
      "torch.Size([2, 2])\n",
      "torch.Size([2, 20, 512, 1024])\n",
      "torch.Size([2, 512, 1024])\n",
      "tensor([0, 0])\n",
      "torch.Size([2, 3, 512, 1024])\n",
      "torch.Size([2, 512, 64, 128])\n",
      "torch.Size([2, 8, 64, 128])\n",
      "torch.Size([2, 8, 9, 18])\n",
      "torch.Size([2, 1296])\n",
      "torch.Size([2, 2])\n",
      "torch.Size([2, 2])\n",
      "torch.Size([2, 20, 512, 1024])\n",
      "torch.Size([2, 512, 1024])\n",
      "tensor([0, 0])\n",
      "torch.Size([2, 3, 512, 1024])\n",
      "torch.Size([2, 512, 64, 128])\n",
      "torch.Size([2, 8, 64, 128])\n",
      "torch.Size([2, 8, 9, 18])\n",
      "torch.Size([2, 1296])\n",
      "torch.Size([2, 2])\n",
      "torch.Size([2, 2])\n",
      "torch.Size([2, 20, 512, 1024])\n",
      "torch.Size([2, 512, 1024])\n",
      "tensor([0, 0])\n",
      "torch.Size([2, 3, 512, 1024])\n",
      "torch.Size([2, 512, 64, 128])\n",
      "torch.Size([2, 8, 64, 128])\n",
      "torch.Size([2, 8, 9, 18])\n",
      "torch.Size([2, 1296])\n",
      "torch.Size([2, 2])\n",
      "torch.Size([2, 2])\n",
      "torch.Size([2, 20, 512, 1024])\n",
      "torch.Size([2, 512, 1024])\n",
      "tensor([0, 0])\n",
      "torch.Size([2, 3, 512, 1024])\n",
      "torch.Size([2, 512, 64, 128])\n",
      "torch.Size([2, 8, 64, 128])\n",
      "torch.Size([2, 8, 9, 18])\n",
      "torch.Size([2, 1296])\n",
      "torch.Size([2, 2])\n",
      "torch.Size([2, 2])\n",
      "torch.Size([2, 20, 512, 1024])\n",
      "torch.Size([2, 512, 1024])\n",
      "tensor([0, 0])\n",
      "torch.Size([2, 3, 512, 1024])\n",
      "torch.Size([2, 512, 64, 128])\n",
      "torch.Size([2, 8, 64, 128])\n",
      "torch.Size([2, 8, 9, 18])\n",
      "torch.Size([2, 1296])\n",
      "torch.Size([2, 2])\n",
      "torch.Size([2, 2])\n",
      "torch.Size([2, 20, 512, 1024])\n",
      "torch.Size([2, 512, 1024])\n",
      "tensor([0, 0])\n",
      "torch.Size([2, 3, 512, 1024])\n",
      "torch.Size([2, 512, 64, 128])\n",
      "torch.Size([2, 8, 64, 128])\n",
      "torch.Size([2, 8, 9, 18])\n",
      "torch.Size([2, 1296])\n",
      "torch.Size([2, 2])\n",
      "torch.Size([2, 2])\n",
      "torch.Size([2, 20, 512, 1024])\n",
      "torch.Size([2, 512, 1024])\n",
      "tensor([0, 0])\n",
      "torch.Size([2, 3, 512, 1024])\n",
      "torch.Size([2, 512, 64, 128])\n",
      "torch.Size([2, 8, 64, 128])\n",
      "torch.Size([2, 8, 9, 18])\n",
      "torch.Size([2, 1296])\n",
      "torch.Size([2, 2])\n",
      "torch.Size([2, 2])\n",
      "torch.Size([2, 20, 512, 1024])\n",
      "torch.Size([2, 512, 1024])\n",
      "tensor([0, 0])\n",
      "torch.Size([2, 3, 512, 1024])\n",
      "torch.Size([2, 512, 64, 128])\n",
      "torch.Size([2, 8, 64, 128])\n",
      "torch.Size([2, 8, 9, 18])\n",
      "torch.Size([2, 1296])\n",
      "torch.Size([2, 2])\n",
      "torch.Size([2, 2])\n",
      "torch.Size([2, 20, 512, 1024])\n",
      "torch.Size([2, 512, 1024])\n",
      "tensor([0, 0])\n",
      "torch.Size([2, 3, 512, 1024])\n",
      "torch.Size([2, 512, 64, 128])\n",
      "torch.Size([2, 8, 64, 128])\n",
      "torch.Size([2, 8, 9, 18])\n",
      "torch.Size([2, 1296])\n",
      "torch.Size([2, 2])\n",
      "torch.Size([2, 2])\n",
      "torch.Size([2, 20, 512, 1024])\n",
      "torch.Size([2, 512, 1024])\n",
      "tensor([0, 0])\n",
      "torch.Size([2, 3, 512, 1024])\n",
      "torch.Size([2, 512, 64, 128])\n",
      "torch.Size([2, 8, 64, 128])\n",
      "torch.Size([2, 8, 9, 18])\n",
      "torch.Size([2, 1296])\n",
      "torch.Size([2, 2])\n",
      "torch.Size([2, 2])\n",
      "torch.Size([2, 20, 512, 1024])\n",
      "torch.Size([2, 512, 1024])\n",
      "tensor([0, 0])\n"
     ]
    }
   ],
   "source": [
    "k=0\n",
    "ress=[]\n",
    "for step, (imgs, label_imgs, img_ids) in enumerate(without_fog):\n",
    "    if k>10:\n",
    "        break;\n",
    "    with torch.no_grad(): # (corresponds to setting volatile=True in all variables, this is done during inference to reduce memory consumption)\n",
    "        imgs = Variable(imgs).cuda() # (shape: (batch_size, 3, img_h, img_w))\n",
    "        label_imgs = Variable(label_imgs.type(torch.LongTensor)).cuda() # (shape: (batch_size, img_h, img_w))\n",
    "        print(imgs.shape)\n",
    "        \n",
    "        outputs, domain = network(x=imgs,alpha=alpha) # (shape: (batch_size, num_classes, img_h, img_w))\n",
    "        print(outputs.shape)\n",
    "        print(label_imgs.shape)\n",
    "        \n",
    "        outputs = outputs.data.cpu().numpy() # (shape: (batch_size, num_classes, 1024, 2048))\n",
    "        pred_label_imgs = np.argmax(outputs, axis=1) # (shape: (batch_size, 1024, 2048))\n",
    "        pred_label_imgs = pred_label_imgs.astype(np.uint8)\n",
    "        domain_label = torch.ones(batch_size)\n",
    "        domain_label = domain_label.long()\n",
    "            \n",
    "        err_t_domain = loss_dn(domain, domain_label)\n",
    "        ress.append(err_t_domain)\n",
    "        _, pred_domain = torch.max(domain,1)\n",
    "        print(pred_domain)\n",
    "\n",
    "        for i in range(pred_label_imgs.shape[0]):\n",
    "            pred_label_img = pred_label_imgs[i] # (shape: (img_h, img_w))\n",
    "            img_id = img_ids[i]\n",
    "            img = imgs[i] # (shape: (3, img_h, img_w))\n",
    "\n",
    "            img = img.data.cpu().numpy()\n",
    "            img = np.transpose(img, (1, 2, 0)) # (shape: (img_h, img_w, 3))\n",
    "            img = img*np.array([0.229, 0.224, 0.225])\n",
    "            img = img + np.array([0.485, 0.456, 0.406])\n",
    "            img = img*255.0\n",
    "            img = img.astype(np.uint8)\n",
    "\n",
    "            pred_label_img_color = label_img_to_color(pred_label_img)\n",
    "            overlayed_img = 0.35*img + 0.65*pred_label_img_color\n",
    "            overlayed_img = overlayed_img.astype(np.uint8)\n",
    "\n",
    "            cv2.imwrite(network.model_dir + \"/\" + img_id + \"_overlayed.png\", overlayed_img)\n",
    "        k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test=[]\n",
    "for i in ress:\n",
    "    temp=i.numpy()\n",
    "    test.append(temp)\n",
    "plt.plot(test)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
